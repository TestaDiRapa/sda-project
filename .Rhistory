# Now we run a loop, and for each size i, we extract the coefficients
# from regfit.best for the best model of that size,
# multiply them into the appropriate columns of the test model matrix
# to form the predictions, and compute the test MSE.
val.errors=rep(NA,15)
for(i in 1:15){
coefi = coef(regfit.full,id=i)
pred = test.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((data_validation$new_cases_per_million-pred)^2)
}
# The best model is the one that contains which.min(val.errors) (ten in the book) variables.
val.errors; which.min(val.errors)
coef(regfit.full,which.min(val.errors)) # This is based on training data
# there is no predict() method for regsubsets().
# Since we will be using this function again, we can capture our steps above and write our own predict method.
predict.regsubsets = function(object,newdata,id,...){ # ... <-> ellipsis
form=as.formula(object$call[[2]])
mat=model.matrix(form, newdata)
coefi=coef(object, id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
View(test.mat)
View(pred)
test.mat=model.matrix(new_cases_per_million~.,data_test)
# Now we run a loop, and for each size i, we extract the coefficients
# from regfit.best for the best model of that size,
# multiply them into the appropriate columns of the test model matrix
# to form the predictions, and compute the test MSE.
val.errors=rep(NA,15)
for(i in 1:15){
coefi = coef(regfit.full,id=i)
coefi
pred = test.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((data_validation$new_cases_per_million-pred)^2)
}
coefi
data_validation
pred
type(coef(regfit.full,id=1))
typeof(coef(regfit.full,id=1))
type(log.fit)
typeof(log.fit)
log.fit
coef(regfit.full,id=1)
for(i in 1:15){
coefi = coef(regfit.full,id=i)
mean(data_validation$new_cases_per_million-predict(coefi)^2)
}
for(i in 1:15){
coefi = coef(regfit.full,id=i)
mean(log(data_validation$new_cases_per_million)-predict(log.fit)^2)
}
warnings()
for(i in 1:15){
coefi = coef(regfit.full,id=i)
mean((log(data_validation$new_cases_per_million)-predict(log.fit))^2)
}
mean((log(data_validation$new_cases_per_million)-predict(log.fit))^2)
library(leaps)
library(car)
library(glmnet)
library(ggplot2)
#################################################################
#LOAD DATA
################################################################
setwd("/Users/vincenzo/Documents/GitHub/sda-project")
data = read.csv("covid-data.csv", header=T, sep=",")
columns <- colnames(data)
#all data
data <- data[-c(11654,11743,11747,11748,11749,11736),]
#split into train,test and validation
data_train <- data[which(data$iso_code %in% c('ITA', 'GBR', 'IND', 'JPN', 'ISR', 'LUX', 'AUS', 'AUT', 'NZL', 'ARG', 'BEL', 'CAN', 'ZAF', 'PRT','RUS','TUR')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
data_test = data[which(data$iso_code %in% c('USA','IRN','KOR','URY')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
data_validation = data[which(data$iso_code %in% c('ISL','MEX','DNK','PER')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
data_validation= na.omit(data_validation)
data_train = na.omit(data_train)
data_test = na.omit(data_test)
View(data_train.log)
library(leaps)
library(car)
library(glmnet)
library(ggplot2)
#################################################################
#LOAD DATA
################################################################
setwd("/Users/vincenzo/Documents/GitHub/sda-project")
data = read.csv("covid-data.csv", header=T, sep=",")
columns <- colnames(data)
#all data
data <- data[-c(11654,11743,11747,11748,11749,11736),]
#split into train,test and validation
data_train <- data[which(data$iso_code %in% c('ITA', 'GBR', 'IND', 'JPN', 'ISR', 'LUX', 'AUS', 'AUT', 'NZL', 'ARG', 'BEL', 'CAN', 'ZAF', 'PRT','RUS','TUR')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
data_test = data[which(data$iso_code %in% c('USA','IRN','KOR','URY')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
data_validation = data[which(data$iso_code %in% c('ISL','MEX','DNK','PER')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
#omit NA values
data_validation= na.omit(data_validation)
data_train = na.omit(data_train)
data_test = na.omit(data_test)
# fit a linear model with all predictors (no changes in the response)
fit = lm(new_cases_per_million~.,data_train)
summary(fit)
data_train.log <- data_train
data_train.log$new_cases_per_million <- log(data_train.log$new_cases_per_million + 0.1)
log.fit = lm(new_cases_per_million~.,data_train.log)
summary(log.fit)
mean((data_validation$new_cases_per_million-predict(fit,data_validation))^2)
regfit.full=regsubsets(new_cases_per_million~.,data_train,nvmax = 15)
reg.summary=summary(regfit.full)
val.errors=rep(NA,15)
for(i in 1:15){
coefi = coef(regfit.full,id=i)
val.errors[i]=mean((data_validation$new_cases_per_million-predict(coefi,data_validation))^2)
}
# The best model is the one that contains which.min(val.errors) (ten in the book) variables.
val.errors; which.min(val.errors)
val.mat=model.matrix(new_cases_per_million~.,data_validation)
# Now we run a loop, and for each size i, we extract the coefficients
# from regfit.best for the best model of that size,
# multiply them into the appropriate columns of the test model matrix
# to form the predictions, and compute the test MSE.
attach(data_validation)
val.errors=rep(NA,15)
for(i in 1:15){
coefi = coef(regfit.full,id=i)
pred = val.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((new_cases_per_million-pred)^2)
}
}
# The best model is the one that contains which.min(val.errors) (ten in the book) variables.
val.errors; which.min(val.errors)
coef(regfit.full,which.min(val.errors)) # This is based on training data
val.mat=model.matrix(new_cases_per_million~.,data_validation)
# Now we run a loop, and for each size i, we extract the coefficients
# from regfit.best for the best model of that size,
# multiply them into the appropriate columns of the test model matrix
# to form the predictions, and compute the test MSE.
attach(data_validation)
val.errors=rep(NA,15)
for(i in 1:15){
coefi = coef(regfit.full,id=i)
pred = val.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((new_cases_per_million-pred)^2)
}
# The best model is the one that contains which.min(val.errors) (ten in the book) variables.
val.errors; which.min(val.errors)
coef(regfit.full,which.min(val.errors)) # This is based on training data
# there is no predict() method for regsubsets().
# Since we will be using this function again, we can capture our steps above and write our own predict method.
predict.regsubsets = function(object,newdata,id,...){ # ... <-> ellipsis
form=as.formula(object$call[[2]])
mat=model.matrix(form, newdata)
coefi=coef(object, id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
regfit.full
# building an “X” matrix from data.
val.mat=model.matrix(new_cases_per_million~.,data_validation)
# Now we run a loop, and for each size i, we extract the coefficients
# from regfit.best for the best model of that size,
# multiply them into the appropriate columns of the test model matrix
# to form the predictions, and compute the test MSE.
attach(data_validation)
val.errors=rep(NA,14)
for(i in 1:14){
coefi = coef(regfit.full,id=i)
pred = val.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((new_cases_per_million-pred)^2)
}
# The best model is the one that contains which.min(val.errors) (ten in the book) variables.
val.errors; which.min(val.errors)
coef(regfit.full,which.min(val.errors)) # This is based on training data
# there is no predict() method for regsubsets().
# Since we will be using this function again, we can capture our steps above and write our own predict method.
predict.regsubsets = function(object,newdata,id,...){ # ... <-> ellipsis
form=as.formula(object$call[[2]])
mat=model.matrix(form, newdata)
coefi=coef(object, id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
val.mat=model.matrix(new_cases_per_million~.,data_validation)
# Now we run a loop, and for each size i, we extract the coefficients
# from regfit.best for the best model of that size,
# multiply them into the appropriate columns of the test model matrix
# to form the predictions, and compute the test MSE.
attach(data_validation)
val.errors=rep(NA,14)
for(i in 1:14){
coefi = coef(regfit.full,id=i)
pred = val.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((new_cases_per_million-pred)^2)
}
# The best model is the one that contains which.min(val.errors) (ten in the book) variables.
val.errors; which.min(val.errors)
coef(regfit.full,which.min(val.errors[2:])) # Th
attach(data_validation)
val.errors=rep(NA,14)
for(i in 1:14){
coefi = coef(regfit.full,id=i)
pred = val.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((new_cases_per_million-pred)^2)
}
# The best model is the one that contains which.min(val.errors) (ten in the book) variables.
val.errors; which.min(val.errors)
coef(regfit.full,which.min(val.errors[2:,])) #
attach(data_validation)
val.errors=rep(NA,14)
for(i in 1:14){
coefi = coef(regfit.full,id=i)
pred = val.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((new_cases_per_million-pred)^2)
}
# The best model is the one that contains which.min(val.errors) (ten in the book) variables.
val.errors; which.min(val.errors)
coef(regfit.full,which.min(val.errors[-1])) # This is based
summary(adj.fit)
data = read.csv("covid-data.csv", header=T, sep=",")
columns <- colnames(data)
#all data
data <- data[-c(11654,11743,11747,11748,11749,11736),]
#split into train,test and validation
data_train <- data[which(data$iso_code %in% c('ITA', 'GBR', 'IND', 'JPN', 'ISR', 'LUX', 'AUS', 'AUT', 'NZL', 'ARG', 'BEL', 'CAN', 'ZAF', 'PRT','RUS','TUR')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
data_test = data[which(data$iso_code %in% c('USA','IRN','KOR','URY')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
data_validation = data[which(data$iso_code %in% c('ISL','MEX','DNK','PER')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
adj.fit = lm(new_cases_per_million~.-aged_65_older-aged_70_older-gdp_per_capita-extreme_poverty-female_smokers,data_train)
summary(adj.fit)
fit = lm(new_cases_per_million~.,data_train)
summary(fit)
data_train.log <- data_train
data_train.log$new_cases_per_million <- log(data_train.log$new_cases_per_million + 0.1)
adjlog.fit = lm(new_cases_per_million~.-aged_65_older-aged_70_older-gdp_per_capita-extreme_poverty-female_smokers,data_train.log)
summary(adjlog.fit)
val.mat=model.matrix(new_cases_per_million~.,data_validation)
# Now we run a loop, and for each size i, we extract the coefficients
# from regfit.best for the best model of that size,
# multiply them into the appropriate columns of the test model matrix
# to form the predictions, and compute the test MSE.
val.errors=rep(NA,14)
for(i in 1:14){
coefi = coef(regfit.full,id=i)
pred = val.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((data_validation$new_cases_per_million-pred)^2)
}
# The best model is the one that contains which.min(val.errors) (ten in the book) variables.
print("Errore sul validation della best subset")
val.errors; which.min(val.errors)
coef(regfit.full,which.min(val.errors[-1])) # This is based on training data
print("Errore sul validation di adj.fit")
mean((data_validation$new_cases_per_million-predict(adj.fit,data_validation))^2)
print("errore sul validation di adjfit.log")
mean((log(data_validation$new_cases_per_million)-predict(adjlog.fit,data_validation))^2)
summary(val.errors)
val.mat=model.matrix(new_cases_per_million~.,data_validation)
# Now we run a loop, and for each size i, we extract the coefficients
# from regfit.best for the best model of that size,
# multiply them into the appropriate columns of the test model matrix
# to form the predictions, and compute the test MSE.
val.errors=rep(NA,14)
for(i in 1:14){
coefi = coef(regfit.full,id=i)
pred = val.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((data_validation$new_cases_per_million-pred)^2)
}
print("Errore sul validation di adj.fit")
mean((data_validation$new_cases_per_million-predict(adj.fit,data_validation))^2)
padj.fit=predict(adj.fit,data_validation)
adj.fit
predict(adj.fit,data_validation)
data_validation= na.omit(data_validation)
data_train = na.omit(data_train)
data_test = na.omit(data_test)
val.errors=rep(NA,14)
for(i in 1:14){
coefi = coef(regfit.full,id=i)
pred = val.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((data_validation$new_cases_per_million-pred)^2)
}
# The best model is the one that contains which.min(val.errors) (ten in the book) variables.
print("Errore sul validation della best subset")
val.errors; which.min(val.errors)
coef(regfit.full,which.min(val.errors[-1])) # This is based on training data
print("Errore sul validation di adj.fit")
adj.fit
padj.fit=predict(adj.fit,data_validation)
mean((data_validation$new_cases_per_million-predict(adj.fit,data_validation))^2)
print("errore sul validation di adjfit.log")
mean((log(data_validation$new_cases_per_million)-predict(adjlog.fit,data_validation))^2)
print("errore sul validation di adjfit.log")
log_new_cases_per_million=log(data_validation$new_cases_per_million)
log_new_cases_per_million
data_train.log <- data_train
data_train.log$new_cases_per_million <- log(data_train.log$new_cases_per_million + 0.1)
data_test.log <- data_test
data_test.log$new_cases_per_million <- log(data_test.log$new_cases_per_million + 0.1)
data_validation.log <- data_validation
data_validation.log$new_cases_per_million <- log(data_validation.log$new_cases_per_million + 0.1)
print("errore sul validation di adjfit.log")
log_new_cases_per_million=log(data_validation$new_cases_per_million)
log_new_cases_per_million
mean((log_new_cases_per_million-predict(adjlog.fit,data_validation))^2)
print("errore sul validation di adjfit.log")
mean((log_new_cases_per_million-predict(adjlog.fit,data_validation.log))^2)
print("errore sul validation di adjfit.log")
data_validation.log$new_cases_per_million
mean((log_new_cases_per_million-predict(adjlog.fit,data_validation.log))^2)
# there is no predict() method for regsubsets().
print("errore sul validation di adjfit.log")
data_validation.log$new_cases_per_million
predict(adjlog.fit,data_validation.log)
mean((log_new_cases_per_million-predict(adjlog.fit,data_validation.log))^2)
mean((data_validation.log$new_cases_per_million-predict(adjlog.fit,data_validation.log))^2)
to.plot = data.frame(y_real = data_validation.log$new_cases_per_million, y_pred = predict(adjlog.fit,data_validation.log) )
plot <- ggplot(to.plot) +
geom_line(aes(y=y_real, group=1)) +
geom_line(aes(y=y_pred, group=2))
print(plot)
to.plot = data.frame(y_real = data_validation.log$new_cases_per_million, y_pred = predict(adjlog.fit,data_validation.log) )
plot <- ggplot(to.plot, aes(x=1:length(data_validation.log$new_cases_per_million))) +
geom_line(aes(y=y_real, group=1)) +
geom_line(aes(y=y_pred, group=2))
print(plot)
help("geom_line")
help(ggplot)
help(geom_line)
vignette("ggplot2-specs")
to.plot = data.frame(y_real = data_validation.log$new_cases_per_million, y_pred = predict(adjlog.fit,data_validation.log) )
plot <- ggplot(to.plot, aes(x=1:length(data_validation.log$new_cases_per_million))) +
geom_line(aes(y=y_real, group=1)) +
geom_line(aes(y=y_pred, group=2,colour="red"))
print(plot)
#IMPORT LIBRARIES
##################################################################
library(leaps)
library(car)
library(glmnet)
library(ggplot2)
#################################################################
#LOAD DATA
################################################################
setwd("/Users/vincenzo/Documents/GitHub/sda-project")
data = read.csv("covid-data.csv", header=T, sep=",")
columns <- colnames(data)
#all data
data <- data[-c(11654,11743,11747,11748,11749,11736),]
#split into train,test and validation
data_train <- data[which(data$iso_code %in% c('ITA', 'GBR', 'IND', 'JPN', 'ISR', 'LUX', 'AUS', 'AUT', 'NZL', 'ARG', 'BEL', 'CAN', 'ZAF', 'PRT','RUS','TUR')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
data_test = data[which(data$iso_code %in% c('USA','IRN','KOR','URY')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
data_validation = data[which(data$iso_code %in% c('ISL','MEX','DNK','PER')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
#omit NA values
data_validation= na.omit(data_validation)
data_train = na.omit(data_train)
data_test = na.omit(data_test)
#BUILD LOG DATASET
data_train.log <- data_train
data_train.log$new_cases_per_million <- log(data_train.log$new_cases_per_million + 0.1)
data_test.log <- data_test
data_test.log$new_cases_per_million <- log(data_test.log$new_cases_per_million + 0.1)
data_validation.log <- data_validation
data_validation.log$new_cases_per_million <- log(data_validation.log$new_cases_per_million + 0.1)
###########################################################################
#FITTING MODELS
##########################################################################
# fit a linear model with all predictors (no changes in the response)
fit = lm(new_cases_per_million~.,data_train)
summary(fit)
# model diagnositic plots
dev.new()
par(mfrow=c(2,2))
plot(fit)
#Refit the model with only the significant predictors
adj.fit = lm(new_cases_per_million~.-aged_65_older-aged_70_older-gdp_per_capita-extreme_poverty-female_smokers,data_train)
summary(adj.fit)
# model diagnositic plots
dev.new()
par(mfrow=c(2,2))
plot(adj.fit)
# fit a linear model with all predictors (log of the response)
data_train.log <- data_train
data_train.log$new_cases_per_million <- log(data_train.log$new_cases_per_million + 0.1)
log.fit = lm(new_cases_per_million~.,data_train.log)
summary(log.fit)
# model diagnositic plots
dev.new()
par(mfrow=c(2,2))
plot(log.fit)
# refit a linear model with only the significant predictors (log of the response)
data_train.log <- data_train
data_train.log$new_cases_per_million <- log(data_train.log$new_cases_per_million + 0.1)
adjlog.fit = lm(new_cases_per_million~.-aged_65_older-aged_70_older-gdp_per_capita-extreme_poverty-female_smokers,data_train.log)
summary(adjlog.fit)
# model diagnositic plots
dev.new()
par(mfrow=c(2,2))
plot(adjlog.fit)
#################################################################################
#BESTSUBSET SELECTION
#####################################################################################
regfit.full=regsubsets(new_cases_per_million~.,data_train,nvmax = 15)
reg.summary=summary(regfit.full)
#model diagnostic plots
dev.new()
par(mfrow=c(2,2))
#RSS PLOT
plot(reg.summary$rss ,xlab="Number of Variables ",ylab="RSS",type="l")
points(which.min(reg.summary$rss),min(reg.summary$rss), col="red",cex=2,pch=20)
#ADJUSTED R**2 PLOT
plot(reg.summary$adjr2 ,xlab="Number of Variables ",ylab="Adjusted RSq",type="l")
points(which.max(reg.summary$adjr2),max(reg.summary$adjr2), col="red",cex=2,pch=20)
#MALLOW'S CP PLOT
plot(reg.summary$cp ,xlab="Number of Variables ",ylab="Cp", type="l")
points(which.min(reg.summary$cp ),min(reg.summary$cp),col="red",cex=2,pch=20)
#BIC PLOT
plot(reg.summary$bic ,xlab="Number of Variables ",ylab="BIC",type="l")
points(which.min(reg.summary$bic),min(reg.summary$bic),col="red",cex=2,pch=20)
#PLOT HEATMAP'S
dev.new()
plot(regfit.full,scale="r2")
dev.new()
plot(regfit.full,scale="adjr2")
dev.new()
plot(regfit.full,scale="Cp")
dev.new()
plot(regfit.full,scale="bic")
########################################
#ANOVA TEST between bestsubset with 3 and 6 predictors
anova(coef(regfit.full,id=3),coef(regfit.full,id=6))
coef(regfit.full,id=3)
anova)=
anova()
anova(coef(regfit.full,id=3),coef(regfit.full,id=6))
#IMPORT LIBRARIES
##################################################################
library(leaps)
library(car)
library(glmnet)
library(ggplot2)
#################################################################
#LOAD DATA
################################################################
setwd("/Users/vincenzo/Documents/GitHub/sda-project")
data = read.csv("covid-data.csv", header=T, sep=",")
columns <- colnames(data)
#all data
data <- data[-c(11654,11743,11747,11748,11749,11736),]
#split into train,test and validation
data_train <- data[which(data$iso_code %in% c('ITA', 'GBR', 'IND', 'JPN', 'ISR', 'LUX', 'AUS', 'AUT', 'NZL', 'ARG', 'BEL', 'CAN', 'ZAF', 'PRT','RUS','TUR')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
data_test = data[which(data$iso_code %in% c('USA','IRN','KOR','URY')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
data_validation = data[which(data$iso_code %in% c('ISL','MEX','DNK','PER')),columns[c(10,15,16,20,21,22,23,24,25,26,27,28,29,30,31)]]
#omit NA values
data_validation= na.omit(data_validation)
data_train = na.omit(data_train)
data_test = na.omit(data_test)
#BUILD LOG DATASET
data_train.log <- data_train
data_train.log$new_cases_per_million <- log(data_train.log$new_cases_per_million + 0.1)
data_test.log <- data_test
data_test.log$new_cases_per_million <- log(data_test.log$new_cases_per_million + 0.1)
data_validation.log <- data_validation
data_validation.log$new_cases_per_million <- log(data_validation.log$new_cases_per_million + 0.1)
###########################################################################
fit = lm(new_cases_per_million~.,data_train)
summary(fit)
vif(fit)
dev.new()
par(mfrow=c(2,2))
plot(fit)
#Refit the model with only the significant predictors
adj.fit = lm(new_cases_per_million~.-aged_65_older-aged_70_older-gdp_per_capita-extreme_poverty-female_smokers,data_train)
summary(adj.fit)
vif(adj.fit)
# fit a linear model with all predictors (no changes in the response)
fit = lm(new_cases_per_million~.,data_train)
summary(fit)
vif(fit)
# model diagnositic plots
dev.new()
par(mfrow=c(2,2))
plot(fit)
#Refit the model with only the significant predictors
adj.fit = lm(new_cases_per_million~.-aged_65_older-aged_70_older-gdp_per_capita-extreme_poverty-female_smokers,data_train)
summary(adj.fit)
vif(adj.fit)
# model diagnositic plots
dev.new()
par(mfrow=c(2,2))
plot(adj.fit)
# fit a linear model with all predictors (log of the response)
data_train.log <- data_train
data_train.log$new_cases_per_million <- log(data_train.log$new_cases_per_million + 0.1)
log.fit = lm(new_cases_per_million~.,data_train.log)
summary(log.fit)
# model diagnositic plots
dev.new()
par(mfrow=c(2,2))
plot(log.fit)
anova(fit,adj.fit)
pairs(data_train)
fit = lm(new_cases_per_million~.,data_train)
summary(fit)
vif(fit)
# model diagnositic plots
dev.new()
par(mfrow=c(2,2))
plot(fit)
pairs(data_train)
pairs(data_train$new_cases_per_million~.,data_train)
pairs(data_train$new_cases_per_million~.,data_train)
pairs(~.,data_train)
pairs(~.,data_train)
pairs(data_train)
